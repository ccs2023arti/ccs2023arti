<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>index</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h1 id="weakcamid-artifact-evaluation---ccs-2023">WeakCamID artifact evaluation - CCS 2023</h1>
<h3 id="weakcamid--brief"><strong>WeakCamID</strong>  Brief</h3>
<p>Wireless security cameras may deter intruders. Accompanying the hardware, consumers may pay recurring monthly fees for recording videos to the cloud, or use the free tier offering motion alerts and sometimes live streams via the camera app. Many users may purchase the hardware without buying the subscription to save money, which inherently reduces their efficacy. We discover that the wireless traffic generated by a camera responding to stimulating motion may disclose whether or not video is being streamed. A malicious user such as a burglar may use such knowledge to target homes with a “weak camera” that does not upload video or turn on live view mode. In such cases, criminal activities would not be recorded though they are performed within the monitoring area of the camera. Accordingly, we describe a novel technique called WeakCamID that creates motion stimuli and sniffs resultant wireless traffic to infer the camera state. We perform a survey involving a total of 220 users, finding that all users think cameras have a consistent security guarantee regardless of the subscription status. Our discovery breaks such “common sense”. We implement <strong>WeakCamID</strong> in a mobile app and experiment with 11 popular wireless cameras to show that <strong>WeakCamID</strong> can identify weak cameras with a mean accuracy of around 95% and within less than 19 seconds.</p>
<p><a href="http://weakcamid.info/paper.pdf">Read our latest version of full paper</a>.</p>
<h2 id="artifact-evaluation-sections">Artifact evaluation sections</h2>
<p>Here are the list of our artifact evaluation materials, and <strong>each item in this guide will lead to an indivinal section of processes we did for get the result</strong>:</p>
<h3 id="artifact-inventory-list---">Artifact inventory list –</h3>
<h5 id="below-are-the-artifacts-that-generate-the-corresponding-results.-we-will-show-the-detailed-data-collecting-methods-and-data-processing-preceduces-in-each-item-in-our-inventory.-each-item-in-this-guide-will-lead-to-an-indivinal-section-of-processes-we-did-for-get-the-result.-click-go-to-button-to-view-individual-artifact-page.">Below are the artifacts that generate the corresponding results. We will show the detailed data collecting methods and data processing preceduces in each item in our inventory. <strong>Each item in this guide will lead to an indivinal section of processes we did for get the result</strong>. Click <code>Go to</code> button to view individual artifact page.</h5>
<hr>
<h5 id="general-analysis-on-the-distinctiveness--of-camera-traffic.-go-to">1. General analysis on the distinctiveness  of camera traffic. <a href="http://motioncompass.info/traffic.html">Go to</a></h5>
<ul>
<li>Identifying camera traffic (Figure 15)</li>
</ul>
<hr>
<h5 id="a-case-study-go-to">2. A case study <a href="http://motioncompass.info/casestudy.html">Go to</a></h5>
<ul>
<li>Localization accuracy (Figure 16)</li>
<li>Localization time (Figure 17)</li>
</ul>
<hr>
<h5 id="impact-of---we-collect-the-traffic-in-a-home-network-to-show-the-camera-traffic-is-different-from-other-normal-traffic.">3. Impact of	 * We collect the traffic in a home network to show the camera traffic is different from other normal traffic.</h5>
<hr>
<h5 id="a-case-study-of-using-blink-xt2-camera-as-target-to-perform-our-motioncompass-localization-method-10-times.-go-to">2. A case study of using Blink XT2 camera as target to perform our MotionCompass localization method 10 times. <a href="http://motioncompass.info/casestudy.html">Go to</a></h5>
<ul>
<li>Localization accuracy (Figure 16)
<ul>
<li>The total localization accuracy of this case study, including x-coordinate, y-coordinate and location error.</li>
</ul>
</li>
<li>Localization time (Figure 17)
<ul>
<li>The localzation time took to finish each try in total of 10 times of trys of performing MotionCompass.</li>
</ul>
</li>
</ul>
<hr>
<h5 id="impact-of-the-performance-when-changing-camera’s-initial-hooking-angle-go-to">3. Impact of the performance when changing camera’s initial hooking angle <a href="http://motioncompass.info/angle.html">Go to</a></h5>
<ul>
<li>Localization error vs. initial angle (Figure 18)</li>
<li>Localization time vs. initial angle (Figure 19)</li>
</ul>
<hr>
<h5 id="impact-of-movementthe-performance-when-changing-human-walking-speed-go-to">4. Impact of movementthe performance when changing human walking speed <a href="http://motioncompass.info/speed.html">Go to</a></h5>
<ul>
<li>Localization error vs. movement speed (Figure 20)</li>
<li>Localization time vs. movement speed (Figure 21)</li>
</ul>
<hr>
<h5 id="overall-localization-performance-1ror-and-time-for-a-camera-belonging-to-g1-with-one-motion-sensor-or-g2-with-two-motion-sensors-as-shown-in-figures-22-and-23-go-to">5. Overall localization performance (1)ror and time for a camera belonging to G1 (with one motion sensor) or G2 (with two motion sensors), as shown in Figures 22 and 23 <a href="http://motioncompass.info/grouptimeinoutdoorresult.html">Go to</a></h5>
<ul>
<li>Mean localization error (Figure 22)</li>
<li>Mean localization time (Figure 23)</li>
</ul>
<hr>
<h5 id="overall-localizwe-test-all-cameras-in-both-indoor-and-outdoor-environments.-for-localizing-each-camera-at-every-selected-location-we-performance-2-25-trials.--then-the-following-two-figures-figure-24-and-25-has-been-generated.-go-to">6. Overall localizWe test all cameras in both indoor and outdoor environments. For localizing each camera at every selected location, we performance (2) 25 trials.  Then the following two figures Figure 24 and 25 has been generated. <a href="http://motioncompass.info/inoutdoorresult.html">Go to</a></h5>
<ul>
<li>Outdoor localization error (Figure 24)</li>
<li>Indoor localization error (Figure 25)</li>
</ul>
<hr>
<h5 id="the-figure-26-plot-the-empirical-cumulative-distribution-functions-cdfs-of-the-localization-errors-d_in-and-d_out-for-different-groups-g1-and-g2-of-cameras-under-indoor-and-outdoor-environments.--the-figure-27-plots-cdfs-of-the-localization-time-t_in-and-t_out-for-different-groups-of-cameras-under-both-environments.go-to">7. The figure 26 plot the empirical cumulative distribution functions (CDFs) of the localization errors <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D_{in}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> for different groups (G1 and G2) of cameras under indoor and outdoor environments.  The figure 27 plots CDFs of the localization time <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{in}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> for different groups of cameras under both environments.<a href="http://motioncompass.info/inoutdoorresult.html">Go to</a></h5>
<ul>
<li>CDFs of <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D_{in}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>D</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">D_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.02778em;">D</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.02778em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> (Figure 26)</li>
<li>CDFs of <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>i</mi><mi>n</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{in}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.311664em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">in</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> and <span class="katex--inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>T</mi><mrow><mi>o</mi><mi>u</mi><mi>t</mi></mrow></msub></mrow><annotation encoding="application/x-tex">T_{out}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height: 0.83333em; vertical-align: -0.15em;"></span><span class="mord"><span class="mord mathnormal" style="margin-right: 0.13889em;">T</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height: 0.280556em;"><span class="" style="top: -2.55em; margin-left: -0.13889em; margin-right: 0.05em;"><span class="pstrut" style="height: 2.7em;"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">o</span><span class="mord mathnormal mtight">u</span><span class="mord mathnormal mtight">t</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height: 0.15em;"><span class=""></span></span></span></span></span></span></span></span></span></span> (Figure 27)</li>
</ul>
<hr>
<h5 id="localization-ontable-3-shows-the-minmaxavg-localization-time-in-seconds-if-multiple-cameras-installed-in-a-same-room.-go-to">78. Localization onTable 3 shows the min/max/avg localization time in seconds if multiple cameras installed in a same room. <a href="http://motioncompass.info/mutiplecam.html">Go to</a></h5>
<ul>
<li>Localization time vs. camera count. (Table 3)</li>
</ul>
<hr>
<h5 id="user-study-we-recruited-5-volunteers-and-asked-each-of-them-to-perform-the-motioncompass-technique-to-figure-out-thelocation-of-a-hidden-wireless-camera-randomly-selected-and-deployed-in-the-a-forementioned-outdoor-or-indoor-environment.--every-participant-performed-25-attempts-for-each-environment.go-to">8. User study We recruited 5 volunteers and asked each of them to perform the MotionCompass technique to figure out thelocation of a hidden wireless camera randomly selected and deployed in the a forementioned outdoor or indoor environment.  Every participant performed 25 attempts for each environment.<a href="http://motioncompass.info/userstudy.html">Go to</a></h5>
<ul>
<li>Localization errors for different users. (Figure 28)</li>
<li>Localization time for different users. (Table 4)</li>
</ul>
<hr>
<h5 id="you-can-read-each-section-in-its-indivdual-page-and-if-you-press-home-button-located-on-both-the-top-and-bottom-of-page-then-you-can-come-back-to-artifact-evaluation-guide-home.">You can read each section in its indivdual page, and if you press <code>Home</code> button located on both the top and bottom of page then you can come back to artifact evaluation guide home.</h5>
<h2 id="cameras-we-use-in-experiment">Cameras we use in experiment</h2>

<table>
<thead>
<tr>
<th>ID</th>
<th>Camera Name</th>
<th>Cloud Recording (Unpaid)</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>Arlo Pro 3</td>
<td>No</td>
</tr>
<tr>
<td>2</td>
<td>Arlo Pro 4</td>
<td>No</td>
</tr>
<tr>
<td>3</td>
<td>Arlo Ultra 2</td>
<td>No</td>
</tr>
<tr>
<td>4</td>
<td>Blink XT2</td>
<td>No</td>
</tr>
<tr>
<td>5</td>
<td>Blink Outdoor</td>
<td>No</td>
</tr>
<tr>
<td>6</td>
<td>Ring Stick Up Cam</td>
<td>No</td>
</tr>
<tr>
<td>7</td>
<td>Ring Spotlight</td>
<td>No</td>
</tr>
<tr>
<td>8</td>
<td>Reolink Argus 2</td>
<td>No</td>
</tr>
<tr>
<td>9</td>
<td>SimpliSafe Cam</td>
<td>No</td>
</tr>
<tr>
<td>10</td>
<td>Wyze Cam Floodlight</td>
<td>No</td>
</tr>
<tr>
<td>11</td>
<td>Wyze Cam Outdoor v2</td>
<td>No</td>
</tr>
</tbody>
</table><h2 id="software-prerequisites">Software prerequisites</h2>
<p>The following software/modules needed to get our result:</p>
<ul>
<li>Python 3.9
<ul>
<li>Scikit-learn 0.24</li>
<li>Numpy 1.13.3</li>
<li>Scipy 0.19.1</li>
<li>matplotlib 2.1.1</li>
</ul>
</li>
<li>Matlab R2023_a
<ul>
<li>Machine learning toolkit</li>
<li>Deep Learning toolkit</li>
</ul>
</li>
<li>Microsoft Excel 2023</li>
</ul>
<p>The following <a href="http://motioncompass.info/app.html">Android APP</a> is used to do the experiment and getting the localization result. You can download the APK <a href="http://motioncompass.info/apk.zip">here.</a></p>
<p>You can send us any email if you meet problems when running our code or getting any result, Yan He (<a href="mailto:heyan@ou.edu">heyan@ou.edu</a>) or Fang Song (<a href="mailto:songf@ou.edu">songf@ou.edu</a>).</p>
<h2 id="examples-when-running-our-code">Examples when running our code</h2>
<p>When you entering the indivdual artifact evaluation section page. You will see what kind of tool(s) we use for getting our result. Generally, if we are using python to do the data visualization then here is the how to get you started:</p>
<pre class=" language-python"><code class="prism  language-python">python3 <span class="token punctuation">[</span>section name<span class="token punctuation">]</span><span class="token punctuation">.</span>py 
</code></pre>
<p>If you notice that we are using mathlab to show our final result and you want to  find <code>Matlab</code>  codes we shown on our paper with same result, read <code>Code</code> part which should be on the bottom of each section page.</p>
<pre><code>1. Download the Matlab file with associte data
   (*.zip format) shown on the page.
2. Open *.m file after unzip the file.
3. Run the *.m file on Matlab.
</code></pre>
<p>If the result is getting by Microsoft Excel, just simplely download the *.xls file shown on the individual page.</p>
<h2 id="local-version-of-all-files">Local version of all files</h2>
<h3 id="if-you-need-to-access-the-raw-file-structure-here-is-the-link-to-download-an-off-line-version-of-our-codesdataapp-link">If you need to access the raw file structure, here is the link to download an off-line version of our codes/data/app <a href="http://motioncompass.info/full.zip">LINK</a></h3>
</div>
</body>

</html>
